import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score
data = pd.read_csv('/content/final_merged_file.csv')

#Polynomial Features
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(data[['time', 'input_voltage']])

# Target Variable
y = data['el_power']

# Train-Validation-Test Split
X_train, X_temp, y_train, y_temp = train_test_split(X_poly, y, test_size=0.25, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Data Standardization
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Hyperparameter Tuning 
param_grid = {'alpha': np.logspace(-3, 3, 100)}  # Wider range of alpha values
kf = KFold(n_splits=7, shuffle=True, random_state=42)
ridge_model = Ridge()
grid_search = GridSearchCV(ridge_model, param_grid, cv=kf, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

# Implementing the Best Model
best_model = grid_search.best_estimator_
best_alpha = grid_search.best_params_['alpha']

train_pred = best_model.predict(X_train)
val_pred = best_model.predict(X_val)
test_pred = best_model.predict(X_test)

# Calculating Metrics
train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))

train_r2 = r2_score(y_train, train_pred)
val_r2 = r2_score(y_val, val_pred)
test_r2 = r2_score(y_test, test_pred)

# Displaying Results
print(f"Best Alpha: {best_alpha}")
print(f"Train RMSE: {train_rmse}, Validation RMSE: {val_rmse}, Test RMSE: {test_rmse}")
print(f"Train R² Score: {train_r2}, Validation R² Score: {val_r2}, Test R² Score: {test_r2}")

epochs = np.arange(1, 7)  # Example epochs
train_rmse_history = [train_rmse for _ in epochs]  # Replace with actual values during training
val_rmse_history = [val_rmse for _ in epochs]  # Replace with actual values during training

# Plotting RMSE score vs Epochs
plt.figure(figsize=(12, 6))
plt.plot(epochs, train_rmse_history, label='Train RMSE', marker='o')
plt.plot(epochs, val_rmse_history, label='Validation RMSE', marker='x')
plt.title('Training and Validation RMSE Over the Epochs')
plt.xlabel('Epochs')
plt.ylabel('RMSE score')
plt.legend()
plt.grid()
plt.show()



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score
data = pd.read_csv('/content/final_merged_file.csv')

# Features and Target Variable
X = data[['time', 'input_voltage']]
y = data['el_power']

# Splitting the dataset into train, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Data Standarization
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Ridge regression 
alphas = np.logspace(-3, 3, 100)
ridge_cv = GridSearchCV(Ridge(), {'alpha': alphas}, cv=5)
ridge_cv.fit(X_train_scaled, y_train)
best_ridge = ridge_cv.best_estimator_
best_alpha = ridge_cv.best_params_['alpha']

y_train_pred = best_ridge.predict(X_train_scaled)
y_val_pred = best_ridge.predict(X_val_scaled)
y_test_pred = best_ridge.predict(X_test_scaled)

# Calculating the RMSE and R² Scores
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

train_r2 = r2_score(y_train, y_train_pred)
val_r2 = r2_score(y_val, y_val_pred)
test_r2 = r2_score(y_test, y_test_pred)

# Displaying the results
print(f'Best Alpha: {best_alpha}')
print(f'Train RMSE: {train_rmse}, Validation RMSE: {val_rmse}, Test RMSE: {test_rmse}')
print(f'Train R² Score: {train_r2}, Validation R² Score: {val_r2}, Test R² Score: {test_r2}')

# Plot Training Loss and Validation Loss in a graph
train_rmse_list = []
val_rmse_list = []

for alpha in alphas:
    ridge = Ridge(alpha=alpha)
    ridge.fit(X_train_scaled, y_train)
    y_train_pred = ridge.predict(X_train_scaled)
    y_val_pred = ridge.predict(X_val_scaled)
    train_rmse_list.append(np.sqrt(mean_squared_error(y_train, y_train_pred)))
    val_rmse_list.append(np.sqrt(mean_squared_error(y_val, y_val_pred)))

plt.figure(figsize=(10, 6))
plt.plot(alphas, train_rmse_list, label='Train RMSE', marker='o')
plt.plot(alphas, val_rmse_list, label='Validation RMSE', marker='x')
plt.xscale('log')
plt.xlabel('alpha')
plt.ylabel('RMSE score')
plt.title('Training Validation and Validation RMSE vs Alpha')
plt.legend()
plt.grid(True)
plt.show()

# Displaying the RMSE score and R2 score
print(f"Training RMSE: {train_rmse}")
print(f"Training R2 Score: {train_r2}")

# Displaying the RMSE score and R2 score
print(f"Test RMSE: {test_rmse}")
print(f"Test R2 Score: {test_r2}")
